{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning\n",
    "# Feature Engineering(Only for Deep Learning)\n",
    "# Feature engineering for Deep Learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Final2.csv')\n",
    "X = data[['thickness', 'size', 'shape', 'adhesion', 'single','nuclei','nucleoli','chromatin','mitosis']]\n",
    "y = data['cancer']\n",
    "\n",
    "\n",
    "# Assuming you have a pandas DataFrame named 'data' with multiple columns to encode\n",
    "# Select the columns you want to encode\n",
    "columns_to_encode =['thickness', 'size', 'shape', 'adhesion', 'single','nuclei','nucleoli','chromatin','mitosis']\n",
    "\n",
    "# Create a new DataFrame to store the encoded columns\n",
    "encoded_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over the columns and perform binary one-hot encoding\n",
    "for column in columns_to_encode:\n",
    "    # Perform binary one-hot encoding using to_categorical\n",
    "    encoded_values = to_categorical(data[column])\n",
    "\n",
    "    # Add the encoded values to the encoded_data DataFrame\n",
    "    encoded_data = pd.concat([encoded_data, pd.DataFrame(encoded_values)], axis=1)\n",
    "\n",
    "# Concatenate the original DataFrame with the encoded DataFrame\n",
    "new_data = pd.concat([data, encoded_data], axis=1)\n",
    "\n",
    "# Save the new data to a CSV file\n",
    "new_data.to_csv('Compeition_data.csv', index=False)\n",
    "\n",
    "# Deep Learning with All features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Compeition_data.csv')\n",
    "X = data.drop('cancer', axis=1).values\n",
    "y = data['cancer'].values\n",
    "# Extract X and y where y is the target values\n",
    "#X = data.drop('Y_p', axis=1).values\n",
    "#y = data['Y_p'].values\n",
    "\n",
    "# convert input data to float\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# Define hyperparameters for model\n",
    "input_dim = X.shape[1]  # use the number of columns in X as the input dimension\n",
    "hidden_layers = 5\n",
    "epochs = [10, 50, 100]\n",
    "batch_size = 40\n",
    "learning_rate = 0.0001\n",
    "k = 5\n",
    "\n",
    "# Print the hyperparameters\n",
    "print('input_dim:', input_dim)\n",
    "print('hidden_layers:', hidden_layers)\n",
    "print('epochs:', epochs)\n",
    "print('batch_size:', batch_size)\n",
    "print('learning_rate:', learning_rate)\n",
    "\n",
    "# define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# define the cross-validation folds for validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "auc_list = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        # fit the model\n",
    "        model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "        # evaluate the model on the test set\n",
    "        loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f'Epoch: {epoch}, Accuracy: {acc}, Loss: {loss}')\n",
    "\n",
    "    # predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_class = np.round(y_pred)\n",
    "\n",
    "    # handle NaN values in predictions\n",
    "    if np.isnan(y_pred).any():\n",
    "        y_pred = np.nan_to_num(y_pred)\n",
    "        \n",
    "    # calculate sensitivity and specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_class).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    accuracy_list.append(accuracy)\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Accuracy: {acc}, Loss: {loss}')\n",
    "    \n",
    "    #AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    auc_list.append(roc_auc)\n",
    "    \n",
    "\n",
    "    # Get predicted probabilities for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    \n",
    "    \n",
    "# Plot ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, label='AUC area',lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print the performance metrics\n",
    "# Accuracy has been measured and printed with loss with specific epochs?\n",
    "# Sensitivity and speticity have been calculated\n",
    "\n",
    "\n",
    "print('Accuracy:', np.mean(accuracy_list))\n",
    "print('Sensitivity:', np.mean(sensitivity_list))\n",
    "print('Specificity:', np.mean(specificity_list))\n",
    "print('AUC:', np.mean(auc_list))\n",
    "print(f'Accuracy: {acc}, Loss: {loss}')\n",
    "\n",
    "# Deep Learning with Two least features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Compeition_data.csv')\n",
    "X = data[['nucleoli','mitosis']]. values\n",
    "y = data['cancer'].values\n",
    "# Extract X and y where y is the target values\n",
    "#X = data.drop('Y_p', axis=1).values\n",
    "#y = data['Y_p'].values\n",
    "\n",
    "# convert input data to float\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# Define hyperparameters for model\n",
    "input_dim = X.shape[1]  # use the number of columns in X as the input dimension\n",
    "hidden_layers = 5\n",
    "epochs = [10, 50, 100]\n",
    "batch_size = 40\n",
    "learning_rate = 0.0001\n",
    "k = 5\n",
    "\n",
    "# Print the hyperparameters\n",
    "print('input_dim:', input_dim)\n",
    "print('hidden_layers:', hidden_layers)\n",
    "print('epochs:', epochs)\n",
    "print('batch_size:', batch_size)\n",
    "print('learning_rate:', learning_rate)\n",
    "\n",
    "# define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# define the cross-validation folds for validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "auc_list = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        # fit the model\n",
    "        model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "        # evaluate the model on the test set\n",
    "        loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f'Epoch: {epoch}, Accuracy: {acc}, Loss: {loss}')\n",
    "\n",
    "    # predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_class = np.round(y_pred)\n",
    "\n",
    "    # handle NaN values in predictions\n",
    "    if np.isnan(y_pred).any():\n",
    "        y_pred = np.nan_to_num(y_pred)\n",
    "        \n",
    "    # calculate sensitivity and specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_class).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    accuracy_list.append(accuracy)\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Accuracy: {acc}, Loss: {loss}')\n",
    "    \n",
    "    #AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    auc_list.append(roc_auc)\n",
    "    \n",
    "\n",
    "    # Get predicted probabilities for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    \n",
    "    \n",
    "# Plot ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, label='AUC area',lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print the performance metrics\n",
    "# Accuracy has been measured and printed with loss with specific epochs?\n",
    "# Sensitivity and speticity have been calculated\n",
    "\n",
    "\n",
    "print('Accuracy:', np.mean(accuracy_list))\n",
    "print('Sensitivity:', np.mean(sensitivity_list))\n",
    "print('Specificity:', np.mean(specificity_list))\n",
    "print('AUC:', np.mean(auc_list))\n",
    "print(f'Accuracy: {acc}, Loss: {loss}')\n",
    "\n",
    "\n",
    "\n",
    "# Support Vector Machine with All Features\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Final2.csv')\n",
    "X = data[['thickness', 'size', 'shape', 'adhesion', 'single','nuclei','nucleoli','chromatin','mitosis']]\n",
    "y = data['cancer']\n",
    "\n",
    "\n",
    "# Building and fit the classifier\n",
    "#clf = SVC(kernel='rbf', gamma=0.01, C=1000)\n",
    "clf = SVC(kernel='rbf', gamma=0.01, C=1000, probability=True)\n",
    "\n",
    "clf.fit(X,y)\n",
    "\n",
    "\n",
    "# Use KFold to define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Initialize variables for ROC curve\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append the metrics to the respective lists\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "    # Calculate predicted probabilities for ROC curve\n",
    "    probas = clf.predict_proba(X_test)[:, 1]\n",
    "    all_probs.extend(probas)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# Print the mean values of the evaluation metrics\n",
    "print(\"Mean Sensitivity:\", sum(sensitivity_list) / len(sensitivity_list))\n",
    "print(\"Mean Specificity:\", sum(specificity_list) / len(specificity_list))\n",
    "print(\"Mean Accuracy:\", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision:\", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall:\", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean AUC Score:\", sum(auc_list) / len(auc_list))\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC area',lw=2)\n",
    "#plt.plot([0, 1], [0, 1], 'k--')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "#plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#SVM or support vector machine learning with Two least features\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Final2.csv')\n",
    "X = data[['nucleoli','mitosis']]\n",
    "y = data['cancer']\n",
    "\n",
    "\n",
    "# Building and fit the classifier\n",
    "#clf = SVC(kernel='rbf', gamma=0.01, C=1000)\n",
    "clf = SVC(kernel='rbf', gamma=0.01, C=1000, probability=True)\n",
    "\n",
    "clf.fit(X,y)\n",
    "\n",
    "\n",
    "# Use KFold to define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Initialize variables for ROC curve\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append the metrics to the respective lists\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "    # Calculate predicted probabilities for ROC curve\n",
    "    probas = clf.predict_proba(X_test)[:, 1]\n",
    "    all_probs.extend(probas)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# Print the mean values of the evaluation metrics\n",
    "print(\"Mean Sensitivity:\", sum(sensitivity_list) / len(sensitivity_list))\n",
    "print(\"Mean Specificity:\", sum(specificity_list) / len(specificity_list))\n",
    "print(\"Mean Accuracy:\", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision:\", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall:\", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean AUC Score:\", sum(auc_list) / len(auc_list))\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC area',lw=2)\n",
    "#plt.plot([0, 1], [0, 1], 'k--')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "#plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Decision Tree Model with All features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "import xgboost as xgb\n",
    "# Load the dataset\n",
    "data = pd.read_csv('wisconsin_breast_cancer - Copy.csv')\n",
    "X = data[['thickness', 'size', 'shape','chromatin', 'adhesion', 'single', 'nucleoli', 'mitosis']]\n",
    "y = data['y']\n",
    "\n",
    "# Create the DecisionTreeClassifier instance\n",
    "clf = DecisionTreeClassifier(max_depth=4, criterion='gini', max_features='log2', splitter='best')\n",
    "\n",
    "# Use KFold to define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Perform cross-validation and obtain the accuracy scores\n",
    "scores = cross_val_score(clf, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print the mean and standard deviation of the accuracy scores\n",
    "print(\"Cross-Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Fit the classifier to the entire dataset\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "probas = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculate the false positive rate (FPR) and true positive rate (TPR)\n",
    "fpr, tpr, thresholds = roc_curve(y, probas)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the AUC score\n",
    "auc_score = roc_auc_score(y, probas)\n",
    "print(\"AUC Score:\", auc_score)\n",
    "\n",
    "# Calculate the Matthews Correlation Coefficient\n",
    "#mcc = matthews_corrcoef(y, probas)\n",
    "#print(\"MCC:\", mcc)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the precision\n",
    "precision = precision_score(y, predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate the recall\n",
    "recall = recall_score(y, predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Decision Tree Model with Two least features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "import xgboost as xgb\n",
    "# Load the dataset\n",
    "data = pd.read_csv('wisconsin_breast_cancer - Copy.csv')\n",
    "X = data[['nucleoli', 'mitosis']]\n",
    "y = data['y']\n",
    "\n",
    "# Create the DecisionTreeClassifier instance\n",
    "clf = DecisionTreeClassifier(max_depth=4, criterion='gini', max_features='log2', splitter='best')\n",
    "\n",
    "# Use KFold to define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Perform cross-validation and obtain the accuracy scores\n",
    "scores = cross_val_score(clf, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print the mean and standard deviation of the accuracy scores\n",
    "print(\"Cross-Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Fit the classifier to the entire dataset\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "probas = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculate the false positive rate (FPR) and true positive rate (TPR)\n",
    "fpr, tpr, thresholds = roc_curve(y, probas)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the AUC score\n",
    "auc_score = roc_auc_score(y, probas)\n",
    "print(\"AUC Score:\", auc_score)\n",
    "\n",
    "# Calculate the Matthews Correlation Coefficient\n",
    "#mcc = matthews_corrcoef(y, probas)\n",
    "#print(\"MCC:\", mcc)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the precision\n",
    "precision = precision_score(y, predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate the recall\n",
    "recall = recall_score(y, predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "\n",
    "# Naive Bayes with All features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Final2.csv')\n",
    "X = data[['thickness', 'size', 'shape', 'adhesion', 'single', 'nuclei', 'nucleoli', 'chromatin', 'mitosis']]\n",
    "y = data['cancer']\n",
    "\n",
    "# Initialize the GaussianNB classifier with smoothing parameter\n",
    "clf = GaussianNB(var_smoothing=1e-9)\n",
    "\n",
    "# Use KFold to define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Initialize variables for ROC curve\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append the metrics to the respective lists\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "    # Calculate predicted probabilities for ROC curve\n",
    "    probas = clf.predict_proba(X_test)[:, 1]\n",
    "    all_probs.extend(probas)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# Print the mean values of the evaluation metrics\n",
    "print(\"Mean Sensitivity:\", sum(sensitivity_list) / len(sensitivity_list))\n",
    "print(\"Mean Specificity:\", sum(specificity_list) / len(specificity_list))\n",
    "print(\"Mean Accuracy:\", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision:\", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall:\", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean AUC Score:\", sum(auc_list) / len(auc_list))\n",
    "\n",
    "# Plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "plt.plot(fpr, tpr, label='AUC area', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Naive Bayes with Two least features\n",
    "# Load the dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Final2.csv')\n",
    "X = data[['nucleoli','mitosis']]\n",
    "y = data['cancer']\n",
    "\n",
    "# Initialize the GaussianNB classifier with smoothing parameter\n",
    "clf = GaussianNB(var_smoothing=1e-9)\n",
    "\n",
    "# Use KFold to define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Initialize variables for ROC curve\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append the metrics to the respective lists\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "    # Calculate predicted probabilities for ROC curve\n",
    "    probas = clf.predict_proba(X_test)[:, 1]\n",
    "    all_probs.extend(probas)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# Print the mean values of the evaluation metrics\n",
    "print(\"Mean Sensitivity:\", sum(sensitivity_list) / len(sensitivity_list))\n",
    "print(\"Mean Specificity:\", sum(specificity_list) / len(specificity_list))\n",
    "print(\"Mean Accuracy:\", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision:\", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall:\", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean AUC Score:\", sum(auc_list) / len(auc_list))\n",
    "\n",
    "# Plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "plt.plot(fpr, tpr, label='AUC area', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Logistic Regression with All features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Final2.csv')\n",
    "X = data[['thickness', 'size', 'shape', 'adhesion', 'single', 'nuclei', 'nucleoli', 'chromatin', 'mitosis']]\n",
    "y = data['cancer']\n",
    "\n",
    "\n",
    "# Initialize the Logistic Regression classifier with the specified parameters\n",
    "clf = LogisticRegression(solver='liblinear', penalty='l2', C=0.01)\n",
    "\n",
    "# Use KFold to define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Initialize variables for ROC curve\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append the metrics to the respective lists\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "    # Calculate predicted probabilities for ROC curve\n",
    "    probas = clf.predict_proba(X_test)[:, 1]\n",
    "    all_probs.extend(probas)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# Print the mean values of the evaluation metrics\n",
    "print(\"Mean Sensitivity:\", sum(sensitivity_list) / len(sensitivity_list))\n",
    "print(\"Mean Specificity:\", sum(specificity_list) / len(specificity_list))\n",
    "print(\"Mean Accuracy:\", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision:\", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall:\", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean AUC Score:\", sum(auc_list) / len(auc_list))\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs, pos_label=1)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label='AUC area', color='blue', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Logistic Regression with Two least features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Final2.csv')\n",
    "X = data[['nucleoli','mitosis']]\n",
    "y = data['cancer']\n",
    "\n",
    "# Initialize the Logistic Regression classifier with the specified parameters\n",
    "clf = LogisticRegression(solver='liblinear', penalty='l2', C=0.01)\n",
    "\n",
    "# Use KFold to define the cross-validation strategy\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Initialize variables for ROC curve\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append the metrics to the respective lists\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "    # Calculate predicted probabilities for ROC curve\n",
    "    probas = clf.predict_proba(X_test)[:, 1]\n",
    "    all_probs.extend(probas)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# Print the mean values of the evaluation metrics\n",
    "print(\"Mean Sensitivity:\", sum(sensitivity_list) / len(sensitivity_list))\n",
    "print(\"Mean Specificity:\", sum(specificity_list) / len(specificity_list))\n",
    "print(\"Mean Accuracy:\", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision:\", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall:\", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean AUC Score:\", sum(auc_list) / len(auc_list))\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs, pos_label=1)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label='AUC area', color='blue', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
